{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETA: ~18 minutes\n",
      "20:29:59.750000 Loading data.\n",
      "20:30:11.019000 Extracting non-probabilities features.\n",
      "\t\t WARNING: Script ini hapus: deviceID, voucherID\n",
      "20:30:44.573000 Splitting dataframes.\n",
      "20:30:44.851000 Extracting cumprob to train_df. (SLOW)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\LENOVO\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:32:48.184000 Extracting prob to tests_df. (SLOW)\n",
      "\t\t append_return_prob_from_two_column: ['articleID', 'colorCode']  ->  ac_prob\n",
      "\t\t append_return_prob_from_two_column: ['articleID', 'sizeCode']  ->  as_prob\n",
      "\t\t append_return_prob_from_two_column: ['customerID', 'productGroup', 'sizeCode']  ->  cps_prob\n",
      "20:33:36.182000 Writing to CSVs. ETA 7 minutes\n",
      "20:37:03.673000 Done\n"
     ]
    }
   ],
   "source": [
    "# Not 100% finished yet\n",
    "\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "LABEL = 'returnQuantity'\n",
    "\n",
    "def extract_non_probabilities_features(df):\n",
    "\n",
    "\t# Deletions\n",
    "\tprint \"\\t\\t WARNING: Script ini hapus: deviceID, voucherID\"\n",
    "\tdel df['deviceID']\n",
    "\tdel df['voucherID']\n",
    "\n",
    "\t# Total price for an order\n",
    "\torder_total_dict = df[['orderID', 'price']].groupby('orderID').sum()['price'].to_dict()\n",
    "\tdf['order_total'] = df.orderID.apply(order_total_dict.get).astype(np.float32)\n",
    "\tdel order_total_dict\n",
    "\n",
    "\t# Average budget of the customer\n",
    "\tcustomer_budget_dict = df[['customerID', 'order_total']].groupby('customerID').mean()['order_total'].to_dict()\n",
    "\tdf['customer_budget'] = df.customerID.apply(customer_budget_dict.get).astype(np.float32)\n",
    "\tdel customer_budget_dict\n",
    "\n",
    "\t# Customer expense ratio\t\n",
    "\ttotal_spent_dict = df[['customerID', 'order_total']].groupby('customerID').sum()['order_total'].to_dict()\n",
    "\tdf['total_spent'] = df.customerID.apply(total_spent_dict.get).astype(np.float32)\n",
    "\tdel total_spent_dict\n",
    "\n",
    "\tdf['expense_ratio'] = (df['customer_budget'] / df['total_spent']).astype(np.float16)\n",
    "\n",
    "\t# Total_spent dihapus. Kalau nggak mau dihapus, comment aja\n",
    "\tdel df['total_spent']\n",
    "\n",
    "\n",
    "\t# 2 baris ini untuk mencegah `quantity = 0`, para infaqers\n",
    "\ttemp_quantity = df.quantity.copy()\n",
    "\ttemp_quantity[temp_quantity==0] = 1\n",
    "\n",
    "\t# unit_price = price / quantity. by @amirahff\n",
    "\tdf['unit_price'] = (df.price/temp_quantity).astype(np.float32)\n",
    "\tdel temp_quantity\n",
    "\n",
    "\t# Median unit price, the usual unit price\n",
    "\tmedian_unit_price_dict = df[['articleID', 'unit_price']].groupby('articleID').median().unit_price.to_dict()\n",
    "\tdf['median_unit_price']=df.articleID.apply(median_unit_price_dict.get).astype(np.float32)\n",
    "\tdel median_unit_price_dict\n",
    "\n",
    "\tdf['price_diff'] = (df['unit_price']-df.median_unit_price).astype(np.float32)\n",
    "\n",
    "\t# Price after discount = order_total - voucherAmount\n",
    "\tdf['after_voucher'] = df.order_total - df.voucherAmount\n",
    "\n",
    "\t# Orders (as in rank)\n",
    "\tdf['order_order']  = df[['customerID', 'orderID']].groupby(['customerID']).cumcount() + 1\n",
    "\tdf['choice_order'] = df[['orderID', 'articleID']].groupby(['orderID']).cumcount() + 1\n",
    "\t\n",
    "\t# Reduce float/int precision\n",
    "\tfloat_64_columns = df.loc[:, df.dtypes == np.float64].columns\n",
    "\tfor col in float_64_columns:\n",
    "\t\tdf[col] = df[col].astype(np.float32)\n",
    "\n",
    "\tint_64_columns = df.loc[:, df.dtypes == np.int64].columns\n",
    "\tfor col in int_64_columns:\n",
    "\t\tdf[col] = df[col].astype(np.int32)\n",
    "\n",
    "\treturn df\n",
    "        \n",
    "def extract_cumprob(df):\n",
    "\n",
    "\tdef append_return_cumprob(df, input_column):\n",
    "\t\ttarget_column_name = input_column + '_cumprob'\n",
    "\n",
    "\t\tdf_temp = df[[input_column, 'returnQuantity','quantity']]\n",
    "\t\tdf_return_probability = df_temp.groupby(input_column)['returnQuantity','quantity'].cumsum()\n",
    "\n",
    "\t\tdf_return_probability[ target_column_name ]  = df_return_probability.returnQuantity / df_return_probability.quantity\n",
    "\t\tdf[ target_column_name ] = df_return_probability[ target_column_name ].replace(np.NaN, 0.5).replace(np.inf, 0.5).apply(lambda x: 1 if x > 1 else x)\n",
    "\t\t\n",
    "\t\tdel df_return_probability\n",
    "        \n",
    "\tdef append_return_cumprob_from_multiple_column(df, input_columns):\n",
    "\t\tcolumn_prefix = ''\n",
    "\t\tfor i in range(0,len(input_columns)):\n",
    "\t\t\tcolumn_prefix = column_prefix + input_columns[i][0]\n",
    "\t\ttarget_column_name = column_prefix + '_prob' \n",
    "\n",
    "\t\tdf_temp = df[ input_columns + ['returnQuantity','quantity'] ]\n",
    "\n",
    "\t\tdf_return_probability = df_temp.groupby(input_columns).cumsum()\n",
    "\t\tdf_return_probability[ target_column_name ]  = df_return_probability.returnQuantity / df_return_probability.quantity\n",
    "\n",
    "\t\tdf[ target_column_name ] = df_return_probability[ target_column_name ].replace(np.NaN, 0.5).replace(np.inf, 0.5).apply(lambda x: 1 if x > 1 else x)\n",
    "\n",
    "\t\tdel df_return_probability\n",
    "\n",
    "\tappend_return_cumprob(df, 'articleID')\n",
    "\tappend_return_cumprob(df, 'colorCode')\n",
    "\tappend_return_cumprob(df, 'customerID')\n",
    "\tappend_return_cumprob(df, 'sizeCode')\n",
    "\n",
    "\tappend_return_cumprob_from_multiple_column(df, ['articleID', 'colorCode'])\n",
    "\tappend_return_cumprob_from_multiple_column(df, ['articleID', 'sizeCode'])\n",
    "\tappend_return_cumprob_from_multiple_column(df, ['customerID', 'productGroup', 'sizeCode'])\n",
    "\n",
    "\treturn df\n",
    "\n",
    "def append_cumprob_to_tests_df(train_df, tests_df):\n",
    "\n",
    "\tdef append_return_prob(column, train_df, tests_df):\n",
    "\t\tdf2 = train_df[[column,'returnQuantity','quantity']]\n",
    "\t\tdf_return_probability = df2.groupby(column).sum()\n",
    "\t\tdf_return_probability[ column + '_prob' ]  = df_return_probability.returnQuantity / df_return_probability.quantity\n",
    "\t\treturn_prob_dict = df_return_probability[ column + '_prob' ].to_dict()\n",
    "\t\tdel df_return_probability\n",
    "\t\ttests_df[ column + '_prob' ] = tests_df[column].apply(return_prob_dict.get).replace(np.NaN, 0.5).replace(np.inf, 0.5).apply(lambda x: 1 if x > 1 else x)\n",
    "\t\tdel return_prob_dict\n",
    "        \n",
    "\tdef append_return_prob_from_multiple_column(input_columns, input_df, target_df):\n",
    "\t\tcolumn_prefix = ''\n",
    "\t\tfor i in range(0,len(input_columns)):\n",
    "\t\t\tcolumn_prefix = column_prefix + input_columns[i][0]\n",
    "\t\ttarget_column_name = column_prefix + '_prob' \n",
    "\n",
    "\t\tprint \"\\t\\t append_return_prob_from_two_column:\", input_columns, ' -> ',target_column_name\n",
    "\n",
    "\t\tdf_temp = input_df[ input_columns + ['returnQuantity','quantity'] ]\n",
    "\n",
    "\t\tdf_return_probability = df_temp.groupby(input_columns).sum()\n",
    "\t\tdf_return_probability[ target_column_name ]  = df_return_probability.returnQuantity / df_return_probability.quantity\n",
    "\n",
    "\t\tprob_dict  = df_return_probability[target_column_name].to_dict()\n",
    "\t\ttarget_df[target_column_name] = target_df[input_columns].apply(tuple, axis=1).apply(prob_dict.get).replace(np.nan, 0.5).replace(np.inf, 0.5)\n",
    "\n",
    "\t\tdel df_return_probability\n",
    "\n",
    "\tappend_return_prob('articleID', train_df, tests_df)\n",
    "\tappend_return_prob('colorCode', train_df, tests_df)\n",
    "\tappend_return_prob('customerID', train_df, tests_df)\n",
    "\tappend_return_prob('sizeCode', train_df, tests_df)\n",
    "\n",
    "\tappend_return_prob_from_multiple_column(['articleID', 'colorCode'], input_df=train_df, target_df=tests_df)\n",
    "\tappend_return_prob_from_multiple_column(['articleID', 'sizeCode'] , input_df=train_df, target_df=tests_df)\n",
    "\tappend_return_prob_from_multiple_column(['customerID', 'productGroup', 'sizeCode'] , input_df=train_df, target_df=tests_df)\n",
    "\n",
    "\treturn tests_df\n",
    "\n",
    "def main():\n",
    "\tfrom datetime import datetime\n",
    "\ttime = lambda: datetime.now().time()\n",
    "\n",
    "\tLABEL = 'returnQuantity'\n",
    "\n",
    "\tprint 'ETA: ~18 minutes'\n",
    "\n",
    "\t#\n",
    "\tprint time(), 'Loading data.'\n",
    "\ttrain_df = pd.read_csv('orders_train.txt', sep=';')\n",
    "\ttests_df = pd.read_csv('orders_class.txt', sep=';')\n",
    "\tdf = pd.concat([train_df, tests_df], axis=0, ignore_index=True)\n",
    "\n",
    "\t# split at the end of train_df index\n",
    "\tsplit = train_df.shape[0]\n",
    "\n",
    "\t# delete train_df & tests_df\n",
    "\t#del train_df\n",
    "\t#del tests_df\n",
    "\n",
    "\t#\n",
    "\tprint time(), 'Extracting non-probabilities features.'\n",
    "\tdf = extract_non_probabilities_features(df)\n",
    "\n",
    "\t#\n",
    "\tprint time(), 'Splitting dataframes.'\n",
    "\n",
    "\ttrain_df = df[:split]\n",
    "\ttests_df = df[split:].drop(LABEL, axis=1)\n",
    "\n",
    "\t#\n",
    "\tprint time(), 'Extracting cumprob to train_df. (SLOW)'\n",
    "\ttrain_df = extract_cumprob(train_df)\n",
    "\n",
    "\t#\n",
    "\tprint time(), 'Extracting prob to tests_df. (SLOW)'\n",
    "\ttests_df = append_cumprob_to_tests_df(train_df, tests_df)\n",
    "\n",
    "\t#\n",
    "\tprint time(), 'Writing to CSVs. ETA 7 minutes'\n",
    "\n",
    "\ttrain_df.to_csv('train_gue2.csv', index=False)\n",
    "\ttests_df.to_csv('tests_gue2.csv', index=False)\n",
    "\n",
    "\t#\n",
    "\tprint time(), 'Done'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
