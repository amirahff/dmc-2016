#### Amirah

kalau yg SelectKBest itu kalau ga salah di LR itu buat meminimalisir error ada metode subset selection sm shrinkage methods, nah yg shrinkage itu yg ridge sm lasso itu.
SelectKBest itu yg subset selection po ya?
ngga tau sih, aku cuma liat sekilas yg subset selection itu wkwk
dia kuat di statistiknya ya
si gliganu
trs covariance itu kalau ngga salah buat neliti kedependenan satu variabel da variabel lainnya

aku baca kan kmrn, kalau mau mentransformasi atribut kita (entah dipangkatin dilog, dll), itu pertamanya hrs nganalisis residual plot gt trs hitung apanyaa gt, R2 kalau ga salah, trs nanti dicoba-coba macam2 transformasinya, setelah dicoba diliat nilai R2 nya kalau lebih kecil (?) dr R2 sblm transformasi berarti transformasinya bener, kalau nggak coba transformasi yg lain

#### Rilut
residual kok kaya data time series sih. yang di-decompose gitu?
emg data kaya gini bisa?
btw di-cluster itu sebetulnya biar apa ya?

#### Amirah
entahlah ,_,
coba ntar tak cek lagi

#### Rilut
ini r2 yang itu kan? http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html
sklearn.metrics.r2_score â€” scikit-learn 0.17.1 documentation
Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.
scikit-learn.org

#### Amirah
cuma mau tau aja, siapa tau mereka berdekatan atau gmn (jaraknya atau apanya)
http://stattrek.com/regression/linear-transformation.aspx?Tutorial=AP
iya yg itu, namanya sama ahaha
eh ralat R2 nya harus semakin gede
